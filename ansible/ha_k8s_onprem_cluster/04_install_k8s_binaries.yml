# TODO: Fix the checks before joining more nodes, check if tokens are OK and control plane is alive.
# Fix the kubeconfig
- hosts: k8s
  remote_user: testing 
  become: true
  vars:
    k8s_version: 1.19.0-00
  tasks:
  - name: "Add Google GPG Key"
    shell: |
      sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg

  - name: Add Kubernetes Repository for Ubuntu/Debian
    apt_repository:
      repo: "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main"

  - name: Install K8s packages with specific version
    apt:
      pkg:
        - "kubelet={{ k8s_version }}"
        - "kubeadm={{ k8s_version }}"
        - "kubectl={{ k8s_version }}"
      state: latest
      update_cache: true
  - name: Hold kubeadm
    dpkg_selections:
      name: "{{ item }}"
      selection: hold
    with_items:
    - kubeadm
    - kubectl
    - kubelet

    # sudo kubeadm init --apiserver-advertise-address {{ node_floating_ip_addr }} --experimental-upload-certs --pod-network-cidr=192.168.0.0/16 > /etc/kubernetes/cluster-bootstrap.log
  - name: Prepare control plane on master node 01
    shell: |
      sudo kubeadm init --control-plane-endpoint "k8s-ha:6443" --upload-certs --pod-network-cidr=192.168.0.0/16 > /etc/kubernetes/cluster-bootstrap.log
    when: "'k8s-master1' in inventory_hostname"

    # Add here output for kubeadm init from below

  - name: Register join token master
    shell: grep -A2 "kubeadm join" /etc/kubernetes/cluster-bootstrap.log | head -n 3
    register: r_join_token_command_master
    changed_when: false
    ignore_errors: true
    when: "'k8s-master1' in inventory_hostname"

  - name: Register join token workers
    shell: grep -A1 "kubeadm join" /etc/kubernetes/cluster-bootstrap.log | tail -n 2
    register: r_join_token_command_worker
    changed_when: false
    ignore_errors: true
    when: "'k8s-master1' in inventory_hostname"

  # - name: Print join token command Master
  #   debug:
  #     msg: "{{ r_join_token_command_master.stdout }}"
  #   when: "'k8s-master1' in inventory_hostname"
  
  - name: Create var from master token
    set_fact:
      master_token_cmd={{ r_join_token_command_master.stdout }}
    when: "'k8s-master1' in inventory_hostname"
  
  - name: Create var from master token
    set_fact:
      worker_token_cmd={{ r_join_token_command_worker.stdout }}
    when: "'k8s-master1' in inventory_hostname"

  # - name: Print join token command Worker
  #   debug:
  #     msg: "{{ r_join_token_command_worker.stdout }}"
  #   when: "'k8s-master1' in inventory_hostname"

  - name: Ensures /home/{{ ansible_user }}/.kube dir exists
    file: 
      path: "/home/{{ ansible_user }}/.kube" 
      state: directory

  - name: Copy K8s config to use kubectl
    copy:
      src: /etc/kubernetes/admin.conf
      dest: "/home/{{ ansible_user }}/.kube/config"
      remote_src: true
    when: "'k8s-master1' in inventory_hostname"

  - name: Install Calico as CNI plugin
    # shell: "kubectl --kubeconfig='/home/{{ ansible_user }}/.kube/config' apply -f https://docs.projectcalico.org/manifests/calico.yaml"
    shell: |
      kubectl --kubeconfig='/home/{{ ansible_user }}/.kube/config' apply -f https://docs.projectcalico.org/archive/v3.16/manifests/tigera-operator.yaml
      kubectl --kubeconfig='/home/{{ ansible_user }}/.kube/config' apply -f https://docs.projectcalico.org/archive/v3.16/manifests/custom-resources.yaml
    when: "'k8s-master1' in inventory_hostname"

  - name: Join rest of masters
    # shell: "kubectl --kubeconfig='/home/{{ ansible_user }}/.kube/config' apply -f https://docs.projectcalico.org/manifests/calico.yaml"
    shell: |
      sudo {{ hostvars['k8s-master1']['master_token_cmd'] }}
    when: inventory_hostname | regex_search("k8s-master[2-3]")

  - name: Join workers
    shell: |
      sudo {{ hostvars['k8s-master1']['worker_token_cmd'] }}
    when: inventory_hostname | regex_search("k8s-worker\d")